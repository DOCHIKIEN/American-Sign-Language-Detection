{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk  \n",
    "\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "model = load_model('model_check.keras')\n",
    "\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'Delete', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'Space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "\n",
    "class HandGestureApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Sign Language to Text\")\n",
    "        \n",
    "        self.main_frame = tk.Frame(root)\n",
    "        self.main_frame.pack(pady=10)\n",
    "\n",
    "        \n",
    "        self.video_label = tk.Label(self.main_frame, bg=\"black\", width=500, height=400)\n",
    "        self.video_label.grid(row=0, column=0, columnspan=3, pady=10)\n",
    "\n",
    "        self.text_box = tk.Text(self.main_frame, height=3, width=50, font=(\"Arial\", 14))\n",
    "        self.text_box.grid(row=1, column=0, columnspan=3, pady=10)\n",
    "\n",
    "        self.button_frame = tk.Frame(self.main_frame)\n",
    "        self.button_frame.grid(row=2, column=0, columnspan=3, pady=10)\n",
    "\n",
    "        self.clear_button = tk.Button(self.button_frame, text=\"Clear All\", bg=\"lightyellow\", width=15, command=self.clear_text)\n",
    "        self.clear_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.save_button = tk.Button(self.button_frame, text=\"Save to a Text File\", bg=\"lightgreen\", width=20, command=self.save_to_file)\n",
    "        self.save_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.quit_button = tk.Button(self.button_frame, text=\"Quit\", bg=\"red\", width=10, command=self.quit_app)\n",
    "        self.quit_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.run_camera()\n",
    "\n",
    "        self.prev_label = \"\"\n",
    "        self.frame_count = 0\n",
    "        self.required_frames = 8\n",
    "\n",
    "    def clear_text(self):\n",
    "        self.text_box.delete(1.0, tk.END)\n",
    "\n",
    "    def save_to_file(self):\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if file_path:\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(self.text_box.get(1.0, tk.END).strip())\n",
    "            print(f\"Saved text to {file_path}\")\n",
    "\n",
    "    def quit_app(self):\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.root.destroy()\n",
    "\n",
    "    def run_camera(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)  \n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "            with mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.8,\n",
    "                                min_tracking_confidence=0.8) as hands:\n",
    "                result = hands.process(rgb_frame)\n",
    "                if result.multi_hand_landmarks:\n",
    "                    for hand_landmarks in result.multi_hand_landmarks:\n",
    "\n",
    "                        mp_drawing.draw_landmarks(\n",
    "                            frame,\n",
    "                            hand_landmarks,\n",
    "                            mp_hands.HAND_CONNECTIONS,\n",
    "                            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2), \n",
    "                            mp_drawing.DrawingSpec(color=(255, 165, 0), thickness=2) \n",
    "                        )\n",
    "\n",
    "                      \n",
    "                        h, w, _ = frame.shape\n",
    "                        x_min, y_min, x_max, y_max = w, h, 0, 0\n",
    "                        for landmark in hand_landmarks.landmark:\n",
    "                            x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                            x_min, y_min = min(x, x_min), min(y, y_min)\n",
    "                            x_max, y_max = max(x, x_max), max(y, y_max)\n",
    "\n",
    "                        padding = 20\n",
    "                        x_min = max(0, x_min - padding)\n",
    "                        y_min = max(0, y_min - padding)\n",
    "                        x_max = min(w, x_max + padding)\n",
    "                        y_max = min(h, y_max + padding)\n",
    "\n",
    "                        hand_roi = frame[y_min:y_max, x_min:x_max]\n",
    "                        if hand_roi.size > 0: \n",
    "                            hand_resized = cv2.resize(hand_roi, (128, 128))\n",
    "                            hand_resized = hand_resized / 255.0\n",
    "                            hand_resized = np.expand_dims(hand_resized, axis=0)\n",
    "\n",
    "                            prediction = model.predict(hand_resized)[0]\n",
    "                            predicted_label = labels[np.argmax(prediction)]\n",
    "\n",
    " \n",
    "                            if predicted_label == self.prev_label:\n",
    "                                self.frame_count += 1\n",
    "                            else:\n",
    "                                self.frame_count = 1\n",
    "                                self.prev_label = predicted_label\n",
    "\n",
    "                            if self.frame_count >= self.required_frames:\n",
    "                                self.append_to_text(predicted_label)\n",
    "                                self.frame_count = 0\n",
    "\n",
    "                            cv2.putText(\n",
    "                                frame,\n",
    "                                predicted_label,\n",
    "                                (x_min, y_min - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                1,\n",
    "                                (0, 255, 0), \n",
    "                                2,\n",
    "                                cv2.LINE_AA\n",
    "                            )\n",
    "\n",
    "            img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            img_tk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "            self.video_label.imgtk = img_tk\n",
    "            self.video_label.configure(image=img_tk)\n",
    "\n",
    "        self.root.after(10, self.run_camera)\n",
    "\n",
    "    \n",
    "\n",
    "    def append_to_text(self, predicted_label):\n",
    "        current_text = self.text_box.get(1.0, tk.END)[:-1] \n",
    "        self.text_box.delete(1.0, tk.END)\n",
    "\n",
    "        if predicted_label == \"Space\":\n",
    "         \n",
    "            self.text_box.insert(tk.END, current_text + \" \")\n",
    "        elif predicted_label == \"Delete\":\n",
    "            \n",
    "            self.text_box.insert(tk.END, current_text[:-1])\n",
    "        else:\n",
    "           \n",
    "            self.text_box.insert(tk.END, current_text + predicted_label)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = HandGestureApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
